{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ROPE Demo on Google Colab\n",
        "\n",
        "Run the ROPE demo on a Colab GPU and download the results.\n",
        "\n",
        "**Before starting:**\n",
        "1. **Runtime -> Change runtime type -> GPU** (T4 or A100).\n",
        "2. Get a [HuggingFace token](https://huggingface.co/settings/tokens) if you want to use Llama (phi2 works without it).\n",
        "\n",
        "**Option A:** You have the ROPE repo on GitHub -> set `REPO_URL` below and run the clone cell.\n",
        "\n",
        "**Option B:** No GitHub -> zip your local ROPE folder, upload it in cell 2, then run the rest."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Install dependencies and clone or use uploaded ROPE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Check GPU\n",
        "import torch\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "else:\n",
        "    print(\"No GPU. Set Runtime -> Change runtime type -> GPU.\")\n",
        "\n",
        "# Option A: Clone from GitHub (set your repo URL)\n",
        "REPO_URL = \"https://github.com/yourusername/ROPE.git\"  # <-- Change to your repo\n",
        "REPO_DIR = \"ROPE\"\n",
        "\n",
        "if not os.path.isdir(REPO_DIR):\n",
        "    if \"yourusername\" in REPO_URL:\n",
        "        print(\"Set REPO_URL to your repo, or upload a zip of the ROPE folder (Option B below).\")\n",
        "    else:\n",
        "        !git clone --depth 1 \"{REPO_URL}\" \"{REPO_DIR}\"\n",
        "\n",
        "if os.path.isdir(REPO_DIR):\n",
        "    %cd {REPO_DIR}\n",
        "    !pip install -e . -q\n",
        "    print(\"ROPE installed.\")\n",
        "else:\n",
        "    print(\"ROPE folder not found. Upload a zip in the next cell (Option B).\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Option B: Upload ROPE zip (if you didn't clone)\n",
        "\n",
        "Zip your local `ROPE` project folder (include `rope/`, `data/`, `pyproject.toml`, etc.), upload below, then re-run cell 1 logic in the next cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run this only if you're uploading a zip. Upload the zip when prompted.\n",
        "from google.colab import files\n",
        "import zipfile\n",
        "\n",
        "uploaded = files.upload()  # Opens file picker\n",
        "for name in uploaded:\n",
        "    if name.endswith('.zip'):\n",
        "        with zipfile.ZipFile(name, 'r') as z:\n",
        "            z.extractall('.')\n",
        "        print(f\"Extracted {name}\")\n",
        "        break\n",
        "# Go to the folder that contains pyproject.toml\n",
        "import os\n",
        "for d in ['ROPE', '.', 'rope-bench']:\n",
        "    if os.path.isfile(os.path.join(d, 'pyproject.toml')):\n",
        "        %cd {d}\n",
        "        !pip install -e . -q\n",
        "        print(f\"Installed from {d}\")\n",
        "        break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. HuggingFace login (for Llama models)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from getpass import getpass\n",
        "from huggingface_hub import login\n",
        "\n",
        "token = getpass(\"Paste your HuggingFace token (or press Enter to skip; phi2 works without it): \")\n",
        "if token.strip():\n",
        "    login(token=token.strip())\n",
        "    print(\"Login successful. Gated models (Llama) will now work.\")\n",
        "else:\n",
        "    print(\"Skipped. Use phi2-only runs (e.g. rope run --models phi2) or add token for Llama.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Run ROPE demo\n",
        "\n",
        "Add `--verbose` to save full debug info (raw judge outputs, defended prompts, etc.)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Standard demo: llama2-7b + 2 defenses + 20 attacks (~5-15 min on T4)\n",
        "# Add --verbose for full debug output\n",
        "!rope demo --verbose"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. View results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "with open(\"demo_results.json\") as f:\n",
        "    results = json.load(f)\n",
        "\n",
        "# Load or compute metrics\n",
        "if os.path.exists(\"demo_results_metrics.csv\"):\n",
        "    metrics = pd.read_csv(\"demo_results_metrics.csv\")\n",
        "else:\n",
        "    from rope.metrics import compute_metrics\n",
        "    metrics = compute_metrics(results)\n",
        "    print(\"Note: CSV not found, computed metrics from JSON.\")\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"OVERALL METRICS\")\n",
        "print(\"=\" * 70)\n",
        "display(metrics)\n",
        "\n",
        "# Per-attack-type breakdown\n",
        "from rope.metrics import compute_by_attack_type, compute_by_task_family\n",
        "by_type = compute_by_attack_type(results)\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"BREAKDOWN BY ATTACK TYPE\")\n",
        "print(\"=\" * 70)\n",
        "display(by_type)\n",
        "\n",
        "# Per-task-family breakdown\n",
        "by_family = compute_by_task_family(results)\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"BREAKDOWN BY TASK FAMILY\")\n",
        "print(\"=\" * 70)\n",
        "display(by_family)\n",
        "\n",
        "print(f\"\\nTotal evaluations: {len(results)}\")\n",
        "print(\"\\nSample result:\")\n",
        "print(json.dumps(results[0], indent=2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Inspect judge outputs (debug)\n",
        "\n",
        "Check what the judge model actually said to verify scoring."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Show judge outputs for the first 10 results\n",
        "for i, r in enumerate(results[:10]):\n",
        "    judge = r.get('judge_output', 'N/A')\n",
        "    print(f\"[{i}] severity={r['severity']}  judge='{judge}'  type={r['attack_type']}  model={r['model']}/{r['defense']}\")\n",
        "\n",
        "# Count severity distribution\n",
        "from collections import Counter\n",
        "sev_dist = Counter(r['severity'] for r in results)\n",
        "print(f\"\\nSeverity distribution: {dict(sorted(sev_dist.items()))}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Download result files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "\n",
        "for name in [\"demo_results.json\", \"demo_results_metrics.csv\", \"demo_results_report.txt\"]:\n",
        "    if os.path.exists(name):\n",
        "        files.download(name)\n",
        "        print(f\"Downloaded {name}\")\n",
        "    else:\n",
        "        print(f\"Not found: {name}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
